{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ojh485/fantasy/blob/main/Fantasy_Football_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Web scraping copied and modified from: https://github.com/logan-lauton/nfl_webscrape/tree/main\n",
    "See below license:**\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2023 Logan Lauton\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (See License)\n",
    "\n",
    "##code to scrape a single seasons data\n",
    "def single(season):\n",
    "    url = f'https://www.pro-football-reference.com/years/{season}/fantasy.htm'\n",
    "    table_html = BeautifulSoup(urlopen(url), 'html.parser').findAll('table')\n",
    "    df = pd.read_html(str(table_html))[0]\n",
    "    df.columns = ['Rk', 'Player', 'Tm', 'FantPos','Age','G','GS','Cmp','P_Att','P_Yds', \\\n",
    "                  'P_TD','Int','R_Att','R_Yds','R_Y/A','R_TD','Re_Tgt','Rec','Re_Y' \\\n",
    "                  , 'Y/R', 'Re_TD','Fmb', 'FL','TD','2PM','2PP', 'FantPt', 'PPR', \\\n",
    "                  'DkPt', 'FDPt', 'VBD', 'PosRank','OvRank'] #renaming columns bc of multi-index\n",
    "\n",
    "    df = df.drop('Rk', axis = 1) # drop Rk columns\n",
    "    df.Player = df.Player.str.replace('*','') # remove asterisk on player's name\n",
    "    df.Player = df.Player.str.replace('+','') # remove plus on player's name\n",
    "    df.insert(0,'Season',season) # insert season column\n",
    "    df = df.apply(pd.to_numeric, errors='coerce').fillna(df) # convert non string values to numeric\n",
    "    return df\n",
    "\n",
    "##function to scrape multiple seasons of data at a time\n",
    "def multiple(start_year,end_year):\n",
    "    df = single(start_year)\n",
    "    while start_year < end_year:\n",
    "        time.sleep(4)                     ##code sleeps for 4 seconds between calls as 20 requests per minute\n",
    "        start_year = start_year + 1       ##are allowed meaning only 15 requests per minute will be made here\n",
    "        df = df.append(single(start_year))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##calling for all NFL seasons I deemed 'relevant' for my purposes. (2000-2001 â€“ 2022-23)\n",
    "df = multiple(2000,2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##quick check to ensure both 2000 and 2022 were included in the table\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling and Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##removal of any rows containing the column names\n",
    "df = df[df['Player']!='Player']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing irrelevant columns for fantasy:\n",
    "drop = ['FL', 'PosRank', 'OvRank']\n",
    "df = df.drop(drop, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing to appropriate datatypes\n",
    "df = df.infer_objects()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding relevant column(s): FPP/Game, PPR/Game, HalfPPR/Game\n",
    "df['FPP/G'] = np.where(df['G'] >= 1, df['FantPt'] / df['G'], np.NaN)\n",
    "df['PPR/G'] = np.where(df['G'] >= 1, df['PPR'] / df['G'], np.NaN)\n",
    "\n",
    "halfPPR = (df['FantPt'] + 0.5*df['Rec']) / df['G']\n",
    "df['HalfPPR/G'] = np.where(df['G'] >= 1, halfPPR, np.NaN)\n",
    "df['id'] = df.groupby(['Player', (df['Age'] - df['Season'])]).ngroup()\n",
    "df.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all players that only have one season (besides 2022 rookies)\n",
    "mask = ~(df.duplicated('id', keep = False)) & (df.Season != 2022)\n",
    "temp1 = df[mask]\n",
    "temp2 = pd.merge(df,temp1, indicator=True, how='outer') \\\n",
    "         .query('_merge==\"left_only\"') \\\n",
    "         .drop('_merge', axis=1)\n",
    "df = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saved to drive so no longer need to rerun everything\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "path = '/content/drive/MyDrive/Coding Projects/ML Fantasy Predictions/NFLstats.csv'\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "  df.to_csv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking to verify that no two players were the same age, with the same name\n",
    "#in the same season (if this were the case, my ID assignment wouldn't work)\n",
    "mask = (df.duplicated(['Player', 'Season', 'Age'], keep = False))\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Downloaded File (Start Here After Running Previous Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/content/drive/MyDrive/Personal Coding ML/Coding Projects/ML Fantasy Predictions/NFLstats.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df.drop('Unnamed: 0', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframes based on position:\n",
    "QB = df.loc[df['FantPos'] == 'QB']\n",
    "RB = df.loc[df['FantPos'] == 'RB']\n",
    "WR = df.loc[df['FantPos'] == 'WR']\n",
    "TE = df.loc[df['FantPos'] == 'TE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training data: all years from all players (except their last season)\n",
    "training = df[df.duplicated('id', keep = 'last')]\n",
    "training = training.sort_values(['id','Season'])\n",
    "training = training.reset_index()\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Unnecessary QB data\n",
    "drop = ['Season','Tm', 'FantPos', 'Re_Tgt', 'Rec', 'Re_Y', 'Y/R', 'Re_TD', 'VBD','2PM', '2PP']\n",
    "QB.drop(drop, axis = 1, inplace = True)\n",
    "QB.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Unnecessary RB data\n",
    "drop = ['Season','Tm', 'FantPos', 'Cmp', 'P_Att',\n",
    "       'P_Yds', 'P_TD', 'Int', 'VBD','2PM', '2PP']\n",
    "RB.drop(drop, axis = 1, inplace = True)\n",
    "RB.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Unnecessary WR data\n",
    "drop = ['Season','Tm', 'FantPos', 'Cmp', 'P_Att',\n",
    "       'P_Yds', 'P_TD', 'Int', 'VBD','2PM', '2PP']\n",
    "WR.drop(drop, axis = 1, inplace = True)\n",
    "WR.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Unnecessary TE data\n",
    "drop = ['Season','Tm', 'FantPos', 'Cmp', 'P_Att',\n",
    "       'P_Yds', 'P_TD', 'Int', 'VBD','2PM', '2PP']\n",
    "TE.drop(drop, axis = 1, inplace = True)\n",
    "TE.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QB.sort_values(['id','Age'], inplace = True)\n",
    "QB.reset_index(inplace = True, drop = True)\n",
    "QB.fillna(0, inplace = True)\n",
    "QB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##**QB 1 Year NN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating input data: all years from all QBs except their last season\n",
    "eligible_QBs = QB[QB.duplicated('id', keep = 'last')]\n",
    "eligible_QBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_ids = eligible_QBs.id.unique()\n",
    "eligible_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of QBs we have to train/test with\n",
    "eligible_ids.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly selecting 80% of QBs for training, leaving 20% for testing\n",
    "rng = np.random.default_rng(1)\n",
    "num_training = np.round(eligible_ids.size * 0.8).astype('int')\n",
    "train_ids = rng.choice(eligible_ids, size = num_training, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QB_train_df = QB[QB.id.isin(train_ids)]\n",
    "#getting rid of last season for each QB\n",
    "QB_train_df = QB_train_df[QB_train_df.duplicated('id', keep = 'last')]\n",
    "#converting to numpy array so it can be passed into NN\n",
    "QB_train_data = QB_train_df.drop(['Player', 'id'], axis =1).to_numpy()\n",
    "#creating labels\n",
    "train_indices = QB_train_df.index + 1\n",
    "QB_train_labels = QB.iloc[train_indices,:].loc[:,['FantPt', 'PPR']].to_numpy()\n",
    "\n",
    "QB_test_df = QB[~(QB.id.isin(train_ids))]\n",
    "#getting rid of last season for each QB\n",
    "QB_test_df = QB_test_df[QB_test_df.duplicated('id', keep = 'last')]\n",
    "#converting to numpy array so it can be passed into NN\n",
    "QB_test_data = QB_test_df.drop(['Player', 'id'], axis =1).to_numpy()\n",
    "#creating labels\n",
    "test_indices = QB_test_df.index + 1\n",
    "QB_test_labels = QB.iloc[test_indices,:].loc[:,['FantPt', 'PPR']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following NN \"rules of thumb\" from [this article](https://towardsdatascience.com/17-rules-of-thumb-for-building-a-neural-network-93356f9930af#:~:text=The%20first%20layer%20should%20be,is%20the%20number%20of%20classes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.Input(shape = (21,)),\n",
    "      tf.keras.layers.Dense(units = 256, activation = 'relu'),\n",
    "      tf.keras.layers.Dropout(rate = 0.3),\n",
    "      tf.keras.layers.Dense(units = 128, activation = 'relu'),\n",
    "      tf.keras.layers.Dropout(rate = 0.3),\n",
    "      tf.keras.layers.Dense(units = 2, activation = 'linear')\n",
    "  ])\n",
    "  return model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'mse',\n",
    "              metrics = tf.keras.metrics.RootMeanSquaredError()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "\n",
    "model.fit(QB_train_data, QB_train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Accuracy on Test Dataset:\n",
    "test_loss, test_acc = tf.keras.Sequential.evaluate(self = model,x = QB_test_data, y = QB_test_labels)\n",
    "print('MSE:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Hyperparamter Notes\n",
    "* Seemed to perform better with a low (or no) dropout\n",
    "* More than 3 layers (2 hidden, 1 output) was not better than 3 layers\n",
    "* Diminishing returns on number of epochs after 100. 200 was *slightly* better than 100\n",
    "* Default learning rate of 0.001 was best\n",
    "* Adam and Nadam has very similar performance\n",
    "* Larger number of nodes in a layer seemed to be better when there was dropout\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QB_2022 = df[(df.FantPos == 'QB') & (df.Season == 2022)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QB_2022.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['Season', 'Player', 'Tm', 'FantPos', 'Re_Tgt',\n",
    "       'Rec', 'Re_Y', 'Y/R', 'Re_TD', '2PM', '2PP', 'VBD','id']\n",
    "input = QB_2022.drop(drop, axis = 1).infer_objects().to_numpy()\n",
    "predictions = model.predict(input)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame(predictions, columns = ['FantPt', 'PPR'])\n",
    "prediction_df['Player'] = QB_2022.reset_index(drop = True).Player\n",
    "prediction_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##QB 3 Year NN\n",
    "A network that learns from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only looking at QBs with more than 3 years of data\n",
    "num_seasons = QB.id.value_counts()\n",
    "veteran_ids = num_seasons.index[num_seasons.gt(3)]\n",
    "vetQB = QB[QB.id.isin(veteran_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model (Not Finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = training.loc[:, 'Age':'id']\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(rnn_units):\n",
    "  return tf.keras.layers.LSTM(\n",
    "    rnn_units,\n",
    "    return_sequences=True, #only returns last output of output sequence\n",
    "    recurrent_initializer='glorot_uniform', #initializer for recurrent_kernel weights matrix\n",
    "    recurrent_activation='sigmoid',\n",
    "    stateful=True, #last state at index i in a batch is used as first state for index i in following batch\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the RNN Model ###\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# Layer 1: LSTM with `rnn_units` number of units.\n",
    "model.add(LSTM(64))\n",
    "#model.add(tf.keras.layers.BatchNormalization())\n",
    "# Layer 3: Dense (fully-connected) layer that transforms the LSTM output\n",
    "# into a points prediction. 3 output layers for three different predictions:\n",
    "# Regular, PPR, Half PPR\n",
    "model.add(tf.keras.layers.Dense(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input shape = [batch_size, timesteps, input_dim]\n",
    "model.build([batch_size, None, input.iloc[0].shape[0]])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Batch definition to create training examples ###\n",
    "# player_id is the first player in the new batch\n",
    "def get_player_batch(player_id):\n",
    "  x = input[input.id == player_id]\n",
    "  x.drop('id', axis = 1, inplace = True)\n",
    "  y = x.iloc[-1,:].loc[:, 'FantPt':'PPR']\n",
    "  x.drop(x.iloc[-1:], axis = 0, inplace = True)\n",
    "\n",
    "\n",
    "  '''TODO: construct a list of input sequences for the training batch'''\n",
    "  input_batch = [vectorized_songs[i:i + seq_length] for i in idx]\n",
    "  '''TODO: construct a list of output sequences for the training batch'''\n",
    "  output_batch = [vectorized_songs[i + 1:i + seq_length + 1] for i in idx]\n",
    "\n",
    "  # x_batch, y_batch provide the true inputs and targets for network training\n",
    "  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
    "  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
    "  return x_batch, y_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model Attempt #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating input data: all years from all QBs except their last season\n",
    "eligible_QBs = QB[QB.duplicated('id', keep = 'last')]\n",
    "eligible_QBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_ids = eligible_QBs.id.unique()\n",
    "eligible_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of QBs we have to train/test with\n",
    "eligible_ids.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly selecting 80% of QBs for training, leaving 20% for testing\n",
    "rng = np.random.default_rng(1)\n",
    "num_training = np.round(eligible_ids.size * 0.8).astype('int')\n",
    "train_ids = rng.choice(eligible_ids, size = num_training, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QB_train_df = QB[QB.id.isin(train_ids)]\n",
    "#getting rid of last season for each QB\n",
    "QB_train_df = QB_train_df[QB_train_df.duplicated('id', keep = 'last')]\n",
    "#converting to numpy array so it can be passed into NN\n",
    "QB_train_data = QB_train_df.drop(['Player', 'id'], axis =1).to_numpy()\n",
    "#creating labels\n",
    "train_indices = QB_train_df.index + 1\n",
    "QB_train_labels = QB.iloc[train_indices,:].loc[:,['FantPt', 'PPR']].to_numpy()\n",
    "\n",
    "QB_test_df = QB[~(QB.id.isin(train_ids))]\n",
    "#getting rid of last season for each QB\n",
    "QB_test_df = QB_test_df[QB_test_df.duplicated('id', keep = 'last')]\n",
    "#converting to numpy array so it can be passed into NN\n",
    "QB_test_data = QB_test_df.drop(['Player', 'id'], axis =1).to_numpy()\n",
    "#creating labels\n",
    "test_indices = QB_test_df.index + 1\n",
    "QB_test_labels = QB.iloc[test_indices,:].loc[:,['FantPt', 'PPR']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding\n",
    "Goal: make one row = one player's career. Add padding to end of the player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QB_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QB_np = QB.to_numpy()\n",
    "QB_career = []*400\n",
    "print(QB_career)\n",
    "QB_counter = 0\n",
    "num_rows, num_cols = QB_np.shape\n",
    "for idx,qb in enumerate(QB_np):\n",
    "  np.append(QB_career[QB_counter], qb)\n",
    "  if idx < num_rows - 1:\n",
    "    #if next QB is different from current, then we update the career idx by 1\n",
    "    if qb[-1] != QB_np[idx + 1][-1]:\n",
    "      QB_counter += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.Input(shape = (21,)),\n",
    "      tf.keras.layers.Dense(units = 256, activation = 'relu'),\n",
    "      tf.keras.layers.Dropout(rate = 0.3),\n",
    "      tf.keras.layers.Dense(units = 128, activation = 'relu'),\n",
    "      tf.keras.layers.Dropout(rate = 0.3),\n",
    "      tf.keras.layers.Dense(units = 2, activation = 'linear')\n",
    "  ])\n",
    "  return model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'mse',\n",
    "              metrics = tf.keras.metrics.RootMeanSquaredError()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "\n",
    "model.fit(QB_train_data, QB_train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Accuracy on Test Dataset:\n",
    "test_loss, test_acc = tf.keras.Sequential.evaluate(self = model,x = QB_test_data, y = QB_test_labels)\n",
    "print('MSE:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOctctdE+aqHXZv343GcOzR",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
